{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f971b4ab",
   "metadata": {},
   "source": [
    "# Data Job Postings Analysis (Hugging Face Dataset)\n",
    "\n",
    "This project analyzes job postings for data-related roles (e.g., Data Analyst, Data Scientist etc.) using the Hugging Face `data_jobs` dataset.  \n",
    "We explore role distribution, skill demand, salary trends, and job locations to uncover hiring patterns in the data field.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5ba35",
   "metadata": {},
   "source": [
    "### 1. Import Libraries & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86c2da2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded - ready to explore data jobs!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "print('Libraries loaded - ready to explore data jobs!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb1c705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Raw dataset loaded and saved to: data_raw/data_jobs_raw.parquet\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "# Create data_raw folder\n",
    "raw_path = Path(\"../data_raw\")\n",
    "raw_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"lukebarousse/data_jobs\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Save raw snapshot to data_raw\n",
    "df.to_parquet(raw_path / \"data_jobs_raw.parquet\", index=False)\n",
    "\n",
    "print(\" Raw dataset loaded and saved to: data_raw/data_jobs_raw.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58c8447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded : (785741, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee México</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer/Scientist/Analyst, Mid or Senior...</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-10 13:14:55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALPHA Augmented Services</td>\n",
       "      <td>['python', 'sql', 'c#', 'azure', 'airflow', 'd...</td>\n",
       "      <td>{'analyst_tools': ['dax'], 'cloud': ['azure'],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        job_title_short                                          job_title  \\\n",
       "0  Senior Data Engineer  Senior Clinical Data Engineer / Principal Clin...   \n",
       "1          Data Analyst                                       Data Analyst   \n",
       "2         Data Engineer  Data Engineer/Scientist/Analyst, Mid or Senior...   \n",
       "\n",
       "                   job_location           job_via job_schedule_type  \\\n",
       "0                 Watertown, CT   via Work Nearby         Full-time   \n",
       "1  Guadalajara, Jalisco, Mexico  via BeBee México         Full-time   \n",
       "2               Berlin, Germany      via LinkedIn         Full-time   \n",
       "\n",
       "   job_work_from_home       search_location      job_posted_date  \\\n",
       "0               False  Texas, United States  2023-06-16 13:44:15   \n",
       "1               False                Mexico  2023-01-14 13:18:07   \n",
       "2               False               Germany  2023-10-10 13:14:55   \n",
       "\n",
       "   job_no_degree_mention  job_health_insurance    job_country salary_rate  \\\n",
       "0                  False                 False  United States        None   \n",
       "1                  False                 False         Mexico        None   \n",
       "2                  False                 False        Germany        None   \n",
       "\n",
       "   salary_year_avg  salary_hour_avg                company_name  \\\n",
       "0              NaN              NaN        Boehringer Ingelheim   \n",
       "1              NaN              NaN  Hewlett Packard Enterprise   \n",
       "2              NaN              NaN    ALPHA Augmented Services   \n",
       "\n",
       "                                          job_skills  \\\n",
       "0                                               None   \n",
       "1  ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "2  ['python', 'sql', 'c#', 'azure', 'airflow', 'd...   \n",
       "\n",
       "                                     job_type_skills  \n",
       "0                                               None  \n",
       "1  {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
       "2  {'analyst_tools': ['dax'], 'cloud': ['azure'],...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the dataset from saved Parquet file\n",
    "\n",
    "df = pd.read_parquet(raw_path / \"data_jobs_raw.parquet\")\n",
    "\n",
    "# Preview shape\n",
    "print(f'Dataset loaded : {df.shape}')\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa981e3c",
   "metadata": {},
   "source": [
    "### 2. Inspect the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61e6817",
   "metadata": {},
   "source": [
    "2.1 Inspect the structure and null values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ceaff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785741 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   job_title_short        785741 non-null  object \n",
      " 1   job_title              785740 non-null  object \n",
      " 2   job_location           784696 non-null  object \n",
      " 3   job_via                785733 non-null  object \n",
      " 4   job_schedule_type      773074 non-null  object \n",
      " 5   job_work_from_home     785741 non-null  bool   \n",
      " 6   search_location        785741 non-null  object \n",
      " 7   job_posted_date        785741 non-null  object \n",
      " 8   job_no_degree_mention  785741 non-null  bool   \n",
      " 9   job_health_insurance   785741 non-null  bool   \n",
      " 10  job_country            785692 non-null  object \n",
      " 11  salary_rate            33067 non-null   object \n",
      " 12  salary_year_avg        22003 non-null   float64\n",
      " 13  salary_hour_avg        10662 non-null   float64\n",
      " 14  company_name           785723 non-null  object \n",
      " 15  job_skills             668704 non-null  object \n",
      " 16  job_type_skills        668704 non-null  object \n",
      "dtypes: bool(3), float64(2), object(12)\n",
      "memory usage: 86.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dd0b19",
   "metadata": {},
   "source": [
    "2.2 Missing values by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "039f786c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary_hour_avg          775079\n",
       "salary_year_avg          763738\n",
       "salary_rate              752674\n",
       "job_type_skills          117037\n",
       "job_skills               117037\n",
       "job_schedule_type         12667\n",
       "job_location               1045\n",
       "job_country                  49\n",
       "company_name                 18\n",
       "job_via                       8\n",
       "job_title                     1\n",
       "job_title_short               0\n",
       "job_work_from_home            0\n",
       "job_no_degree_mention         0\n",
       "job_posted_date               0\n",
       "search_location               0\n",
       "job_health_insurance          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3dfac0",
   "metadata": {},
   "source": [
    "2.3 Descriptive statistics (Numerical columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6bcfdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22003.000000</td>\n",
       "      <td>10662.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>123286.274072</td>\n",
       "      <td>47.016598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>48312.449482</td>\n",
       "      <td>21.890738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15000.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90000.000000</td>\n",
       "      <td>27.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>115000.000000</td>\n",
       "      <td>45.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>150000.000000</td>\n",
       "      <td>61.159996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>960000.000000</td>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       salary_year_avg  salary_hour_avg\n",
       "count     22003.000000     10662.000000\n",
       "mean     123286.274072        47.016598\n",
       "std       48312.449482        21.890738\n",
       "min       15000.000000         8.000000\n",
       "25%       90000.000000        27.500000\n",
       "50%      115000.000000        45.980000\n",
       "75%      150000.000000        61.159996\n",
       "max      960000.000000       391.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c6d6b9",
   "metadata": {},
   "source": [
    "2.4 Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d2b59fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(101)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd38cdbf",
   "metadata": {},
   "source": [
    "2.5 Unique value counts for key columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab31703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_title_short unique values: 10\n",
      "job_country unique values: 160\n",
      "company_name unique values: 139982\n",
      "job_schedule_type unique values: 47\n"
     ]
    }
   ],
   "source": [
    "for col in ['job_title_short', 'job_country', 'company_name', 'job_schedule_type']:\n",
    "    print(f\"{col} unique values:\", df[col].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ccecdd",
   "metadata": {},
   "source": [
    "2.6 Data range check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a9a873e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2023-01-01 00:00:04', '2023-12-31 23:59:58')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job_posted_date'].min(), df['job_posted_date'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec341c",
   "metadata": {},
   "source": [
    "### 3. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99ed1977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip whitespace and standardize column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Clean job_skills_column\n",
    "df['job_skills'] = df['job_skills'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Convert job_posted_date to datetime format\n",
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'], errors = 'coerce')\n",
    "\n",
    "# Drop mostly empty columns\n",
    "df.drop(columns=['salary_hour_avg', 'salary_rate'], inplace = True)\n",
    "\n",
    "# Drop rows where job_title is missing\n",
    "df = df.dropna(subset =['job_title'])\n",
    "\n",
    "#  Fill missing values\n",
    "df.loc[:,'job_schedule_type'] = df['job_schedule_type'].fillna('Unknown')\n",
    "df.loc[:,'job_location'] = df['job_location'].fillna('Unknown')\n",
    "df.loc[:,'job_country'] = df['job_country'].fillna('Unknown')\n",
    "df.loc[:,'company_name'] = df['company_name'].fillna('Unknown')\n",
    "df.loc[:,'job_via'] = df['job_via'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a4749",
   "metadata": {},
   "source": [
    "### 4 Final Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "408615d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>612876</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Senior BI Engineer</td>\n",
       "      <td>Poland</td>\n",
       "      <td>via Trabajo.org</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Poland</td>\n",
       "      <td>2023-02-14 12:37:57</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Poland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Luxoft Poland Sp. z o.o.</td>\n",
       "      <td>[python, databricks, react, microstrategy, tab...</td>\n",
       "      <td>{'analyst_tools': ['microstrategy', 'tableau']...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327015</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Sr data engineer</td>\n",
       "      <td>Corona, CA</td>\n",
       "      <td>via Talent.com</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-06-26 00:14:26</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supernal</td>\n",
       "      <td>[sql, azure, snowflake, bigquery, aws, redshif...</td>\n",
       "      <td>{'cloud': ['azure', 'snowflake', 'bigquery', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149109</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Australia</td>\n",
       "      <td>via BeBee Australia</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023-12-01 08:19:11</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clicks IT Recruitment</td>\n",
       "      <td>[sql, go, sql server, power bi]</td>\n",
       "      <td>{'analyst_tools': ['power bi'], 'databases': [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_title_short           job_title job_location              job_via  \\\n",
       "612876    Data Analyst  Senior BI Engineer       Poland      via Trabajo.org   \n",
       "327015   Data Engineer    Sr data engineer   Corona, CA       via Talent.com   \n",
       "149109    Data Analyst        Data Analyst    Australia  via BeBee Australia   \n",
       "\n",
       "       job_schedule_type  job_work_from_home search_location  \\\n",
       "612876         Full-time               False          Poland   \n",
       "327015         Full-time               False           Sudan   \n",
       "149109         Full-time               False       Australia   \n",
       "\n",
       "           job_posted_date  job_no_degree_mention  job_health_insurance  \\\n",
       "612876 2023-02-14 12:37:57                   True                 False   \n",
       "327015 2023-06-26 00:14:26                  False                 False   \n",
       "149109 2023-12-01 08:19:11                   True                 False   \n",
       "\n",
       "       job_country  salary_year_avg              company_name  \\\n",
       "612876      Poland              NaN  Luxoft Poland Sp. z o.o.   \n",
       "327015       Sudan              NaN                  Supernal   \n",
       "149109   Australia              NaN     Clicks IT Recruitment   \n",
       "\n",
       "                                               job_skills  \\\n",
       "612876  [python, databricks, react, microstrategy, tab...   \n",
       "327015  [sql, azure, snowflake, bigquery, aws, redshif...   \n",
       "149109                    [sql, go, sql server, power bi]   \n",
       "\n",
       "                                          job_type_skills  \n",
       "612876  {'analyst_tools': ['microstrategy', 'tableau']...  \n",
       "327015  {'cloud': ['azure', 'snowflake', 'bigquery', '...  \n",
       "149109  {'analyst_tools': ['power bi'], 'databases': [...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bca811",
   "metadata": {},
   "source": [
    "### 5. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44b595ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('../data_processed/data_jobs_cleaned.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585bc54e",
   "metadata": {},
   "source": [
    "### Data Cleaning Summary\n",
    "\n",
    "- Standardized column names: Stripped whitespace, converted to lowercase, and replaced spaces with underscores for consistency.\n",
    "\n",
    "- Converted job_posted_date to datetime: Enables proper time-based analysis and trend exploration.\n",
    "\n",
    "- Dropped mostly empty columns: Removed salary_hour_avg and salary_rate due to excessive missing values and redundancy.\n",
    "\n",
    "- Retained salary_year_avg: Preserved for potential salary trend analysis — to be filtered or imputed as needed during analysis.\n",
    "\n",
    "- Dropped 1 row with missing job_title: A core identifying field, so rows without it were removed.\n",
    "\n",
    "- Filled moderate nulls in categorical columns: Replaced missing values in fields like job_schedule_type, job_location, company_name, etc., with 'Unknown' for completeness.\n",
    "\n",
    "- Used .loc assignment: Avoided SettingWithCopyWarning by using .loc to safely update DataFrame columns.\n",
    "\n",
    "- Duplicate Removal – Deferred\n",
    "\n",
    "While attempting to remove duplicate rows, a TypeError was encountered due to unhashable data types (e.g., Python lists in the job_skills column).\n",
    "Because these list-based columns are important for downstream analysis, duplicates were not removed at this stage.\n",
    "\n",
    "This step may be revisited after transforming or narrowing down the relevant columns for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3a1bf8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
