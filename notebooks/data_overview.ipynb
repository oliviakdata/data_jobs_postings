{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f971b4ab",
   "metadata": {},
   "source": [
    "# Data Job Postings Analysis (Hugging Face Dataset)\n",
    "\n",
    "This project analyzes job postings for data-related roles (e.g., Data Analyst, Data Scientist etc.) using the Hugging Face `data_jobs` dataset.  \n",
    "We explore role distribution, skill demand, salary trends, and job locations to uncover hiring patterns in the data field.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5ba35",
   "metadata": {},
   "source": [
    "### 1. Import Libraries & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86c2da2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded - ready to explore data jobs!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "print('Libraries loaded - ready to explore data jobs!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cb1c705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Raw dataset loaded and saved to: data_raw/data_jobs_raw.parquet\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "# Create data_raw folder\n",
    "raw_path = Path(\"../data_raw\")\n",
    "raw_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"lukebarousse/data_jobs\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Save raw snapshot to data_raw\n",
    "df.to_parquet(raw_path / \"data_jobs_raw.parquet\", index=False)\n",
    "\n",
    "print(\" Raw dataset loaded and saved to: data_raw/data_jobs_raw.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d58c8447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded : (785741, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee México</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer/Scientist/Analyst, Mid or Senior...</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-10 13:14:55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALPHA Augmented Services</td>\n",
       "      <td>['python', 'sql', 'c#', 'azure', 'airflow', 'd...</td>\n",
       "      <td>{'analyst_tools': ['dax'], 'cloud': ['azure'],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        job_title_short                                          job_title  \\\n",
       "0  Senior Data Engineer  Senior Clinical Data Engineer / Principal Clin...   \n",
       "1          Data Analyst                                       Data Analyst   \n",
       "2         Data Engineer  Data Engineer/Scientist/Analyst, Mid or Senior...   \n",
       "\n",
       "                   job_location           job_via job_schedule_type  \\\n",
       "0                 Watertown, CT   via Work Nearby         Full-time   \n",
       "1  Guadalajara, Jalisco, Mexico  via BeBee México         Full-time   \n",
       "2               Berlin, Germany      via LinkedIn         Full-time   \n",
       "\n",
       "   job_work_from_home       search_location      job_posted_date  \\\n",
       "0               False  Texas, United States  2023-06-16 13:44:15   \n",
       "1               False                Mexico  2023-01-14 13:18:07   \n",
       "2               False               Germany  2023-10-10 13:14:55   \n",
       "\n",
       "   job_no_degree_mention  job_health_insurance    job_country salary_rate  \\\n",
       "0                  False                 False  United States        None   \n",
       "1                  False                 False         Mexico        None   \n",
       "2                  False                 False        Germany        None   \n",
       "\n",
       "   salary_year_avg  salary_hour_avg                company_name  \\\n",
       "0              NaN              NaN        Boehringer Ingelheim   \n",
       "1              NaN              NaN  Hewlett Packard Enterprise   \n",
       "2              NaN              NaN    ALPHA Augmented Services   \n",
       "\n",
       "                                          job_skills  \\\n",
       "0                                               None   \n",
       "1  ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "2  ['python', 'sql', 'c#', 'azure', 'airflow', 'd...   \n",
       "\n",
       "                                     job_type_skills  \n",
       "0                                               None  \n",
       "1  {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
       "2  {'analyst_tools': ['dax'], 'cloud': ['azure'],...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload the dataset from saved Parquet file\n",
    "\n",
    "df = pd.read_parquet(raw_path / \"data_jobs_raw.parquet\")\n",
    "\n",
    "# Preview shape\n",
    "print(f'Dataset loaded : {df.shape}')\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa981e3c",
   "metadata": {},
   "source": [
    "### 2. Inspect the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61e6817",
   "metadata": {},
   "source": [
    "2.1 Inspect the structure and null values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00ceaff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785741 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   job_title_short        785741 non-null  object \n",
      " 1   job_title              785740 non-null  object \n",
      " 2   job_location           784696 non-null  object \n",
      " 3   job_via                785733 non-null  object \n",
      " 4   job_schedule_type      773074 non-null  object \n",
      " 5   job_work_from_home     785741 non-null  bool   \n",
      " 6   search_location        785741 non-null  object \n",
      " 7   job_posted_date        785741 non-null  object \n",
      " 8   job_no_degree_mention  785741 non-null  bool   \n",
      " 9   job_health_insurance   785741 non-null  bool   \n",
      " 10  job_country            785692 non-null  object \n",
      " 11  salary_rate            33067 non-null   object \n",
      " 12  salary_year_avg        22003 non-null   float64\n",
      " 13  salary_hour_avg        10662 non-null   float64\n",
      " 14  company_name           785723 non-null  object \n",
      " 15  job_skills             668704 non-null  object \n",
      " 16  job_type_skills        668704 non-null  object \n",
      "dtypes: bool(3), float64(2), object(12)\n",
      "memory usage: 86.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dd0b19",
   "metadata": {},
   "source": [
    "2.2 Missing values by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "039f786c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary_hour_avg          775079\n",
       "salary_year_avg          763738\n",
       "salary_rate              752674\n",
       "job_type_skills          117037\n",
       "job_skills               117037\n",
       "job_schedule_type         12667\n",
       "job_location               1045\n",
       "job_country                  49\n",
       "company_name                 18\n",
       "job_via                       8\n",
       "job_title                     1\n",
       "job_title_short               0\n",
       "job_work_from_home            0\n",
       "job_no_degree_mention         0\n",
       "job_posted_date               0\n",
       "search_location               0\n",
       "job_health_insurance          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3dfac0",
   "metadata": {},
   "source": [
    "2.3 Descriptive statistics (Numerical columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6bcfdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22003.000000</td>\n",
       "      <td>10662.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>123286.274072</td>\n",
       "      <td>47.016598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>48312.449482</td>\n",
       "      <td>21.890738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15000.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90000.000000</td>\n",
       "      <td>27.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>115000.000000</td>\n",
       "      <td>45.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>150000.000000</td>\n",
       "      <td>61.159996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>960000.000000</td>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       salary_year_avg  salary_hour_avg\n",
       "count     22003.000000     10662.000000\n",
       "mean     123286.274072        47.016598\n",
       "std       48312.449482        21.890738\n",
       "min       15000.000000         8.000000\n",
       "25%       90000.000000        27.500000\n",
       "50%      115000.000000        45.980000\n",
       "75%      150000.000000        61.159996\n",
       "max      960000.000000       391.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c6d6b9",
   "metadata": {},
   "source": [
    "2.4 Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d2b59fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(101)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd38cdbf",
   "metadata": {},
   "source": [
    "2.5 Unique value counts for key columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ab31703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_title_short unique values: 10\n",
      "job_country unique values: 160\n",
      "company_name unique values: 139982\n",
      "job_schedule_type unique values: 47\n"
     ]
    }
   ],
   "source": [
    "for col in ['job_title_short', 'job_country', 'company_name', 'job_schedule_type']:\n",
    "    print(f\"{col} unique values:\", df[col].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ccecdd",
   "metadata": {},
   "source": [
    "2.6 Data range check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a9a873e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2023-01-01 00:00:04', '2023-12-31 23:59:58')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job_posted_date'].min(), df['job_posted_date'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec341c",
   "metadata": {},
   "source": [
    "### 3. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99ed1977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip whitespace and standardize column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Clean job_skills_column\n",
    "df['job_skills'] = df['job_skills'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Convert job_posted_date to datetime format\n",
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'], errors = 'coerce')\n",
    "\n",
    "# Drop mostly empty columns\n",
    "df.drop(columns=['salary_hour_avg', 'salary_rate'], inplace = True)\n",
    "\n",
    "# Drop rows where job_title is missing\n",
    "df = df.dropna(subset =['job_title'])\n",
    "\n",
    "#  Fill missing values\n",
    "df.loc[:,'job_schedule_type'] = df['job_schedule_type'].fillna('Unknown')\n",
    "df.loc[:,'job_location'] = df['job_location'].fillna('Unknown')\n",
    "df.loc[:,'job_country'] = df['job_country'].fillna('Unknown')\n",
    "df.loc[:,'company_name'] = df['company_name'].fillna('Unknown')\n",
    "df.loc[:,'job_via'] = df['job_via'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a4749",
   "metadata": {},
   "source": [
    "### 4 Final Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "408615d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255758</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist For Product, Portfolio And Service</td>\n",
       "      <td>Lisbon, Portugal</td>\n",
       "      <td>via Empregos Trabajo.org</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>2023-08-19 07:24:20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Siemens Mobility</td>\n",
       "      <td>[sql, python, r, snowflake, aws, azure]</td>\n",
       "      <td>{'cloud': ['snowflake', 'aws', 'azure'], 'prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779146</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Marketing Analyst</td>\n",
       "      <td>Madrid, Spain</td>\n",
       "      <td>via BeBee</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Spain</td>\n",
       "      <td>2023-10-02 05:28:05</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jouyll</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432037</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via Jobs Trabajo.org</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-19 16:36:04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plugsurfing GmbH</td>\n",
       "      <td>[python, sql, aws, redshift, gdpr]</td>\n",
       "      <td>{'cloud': ['aws', 'redshift'], 'libraries': ['...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         job_title_short                                          job_title  \\\n",
       "255758    Data Scientist  Data Scientist For Product, Portfolio And Service   \n",
       "779146  Business Analyst                                  Marketing Analyst   \n",
       "432037     Data Engineer                                      Data Engineer   \n",
       "\n",
       "            job_location                   job_via job_schedule_type  \\\n",
       "255758  Lisbon, Portugal  via Empregos Trabajo.org         Full-time   \n",
       "779146     Madrid, Spain                 via BeBee         Full-time   \n",
       "432037   Berlin, Germany      via Jobs Trabajo.org         Full-time   \n",
       "\n",
       "        job_work_from_home search_location     job_posted_date  \\\n",
       "255758               False        Portugal 2023-08-19 07:24:20   \n",
       "779146               False           Spain 2023-10-02 05:28:05   \n",
       "432037               False         Germany 2023-10-19 16:36:04   \n",
       "\n",
       "        job_no_degree_mention  job_health_insurance job_country  \\\n",
       "255758                  False                 False    Portugal   \n",
       "779146                   True                 False       Spain   \n",
       "432037                  False                 False     Germany   \n",
       "\n",
       "        salary_year_avg      company_name  \\\n",
       "255758              NaN  Siemens Mobility   \n",
       "779146              NaN            Jouyll   \n",
       "432037              NaN  Plugsurfing GmbH   \n",
       "\n",
       "                                     job_skills  \\\n",
       "255758  [sql, python, r, snowflake, aws, azure]   \n",
       "779146                                     None   \n",
       "432037       [python, sql, aws, redshift, gdpr]   \n",
       "\n",
       "                                          job_type_skills  \n",
       "255758  {'cloud': ['snowflake', 'aws', 'azure'], 'prog...  \n",
       "779146                                               None  \n",
       "432037  {'cloud': ['aws', 'redshift'], 'libraries': ['...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bca811",
   "metadata": {},
   "source": [
    "### 5. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44b595ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('../data_processed/data_jobs_cleaned.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585bc54e",
   "metadata": {},
   "source": [
    "### Data Cleaning Summary\n",
    "\n",
    "- Standardized column names: Stripped whitespace, converted to lowercase, and replaced spaces with underscores for consistency.\n",
    "\n",
    "- Converted job_posted_date to datetime: Enables proper time-based analysis and trend exploration.\n",
    "\n",
    "- Dropped mostly empty columns: Removed salary_hour_avg and salary_rate due to excessive missing values and redundancy.\n",
    "\n",
    "- Retained salary_year_avg: Preserved for potential salary trend analysis — to be filtered or imputed as needed during analysis.\n",
    "\n",
    "- Dropped 1 row with missing job_title: A core identifying field, so rows without it were removed.\n",
    "\n",
    "- Filled moderate nulls in categorical columns: Replaced missing values in fields like job_schedule_type, job_location, company_name, etc., with 'Unknown' for completeness.\n",
    "\n",
    "- Used .loc assignment: Avoided SettingWithCopyWarning by using .loc to safely update DataFrame columns.\n",
    "\n",
    "- Duplicate Removal – Deferred\n",
    "\n",
    "While attempting to remove duplicate rows, a TypeError was encountered due to unhashable data types (e.g., Python lists in the job_skills column).\n",
    "Because these list-based columns are important for downstream analysis, duplicates were not removed at this stage.\n",
    "\n",
    "This step may be revisited after transforming or narrowing down the relevant columns for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3a1bf8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
